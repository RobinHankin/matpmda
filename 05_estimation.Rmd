# Estimation

Earlier in the course we considered the idea of taking a random sample
from a population.  Often we want to use our sample to gain information
about the population. We will extend that idea in this chapter.

If $X_1, X_2, \ldots, X_n$ are independent random variables having a
common probability distribution, then they form a *sample* from that
distribution.  We have discussed computing some *sample statistics*
sample, such as the sample mean and sample variance.  But observe
carefully that the sample statistics differ from sample to sample,
even if the underlying distribution is unchanged:

```{r}
mean(rnorm(10))
mean(rnorm(10))
mean(rnorm(10))
```

In the above, observe that the standard Gaussian has a mean of exactly
zero, but the sample mean (the average of 10 random observations) has
random variability.

## Sample Statistics vs Population Parameters

Suppose we have observations $x_1,x_2,\ldots x_n$ drawn from a
Gaussian distribution $N(\mu,\sigma)$.  We would like to determine the
value of $\mu$ and $\sigma$ from the observations.  We can calculate
the sample mean of the observations, usually denoted $\overline{x}$
but this does not allow us to pin down the value of $\mu$ exactly,
because we have random variability which is adding noise.


## The Sampling distribution

As we saw above, each time we sample from the Normal distribution
using `rnorm(10)` we get a different sample mean, even the though
the population mean is 0.  The distribution of these sample means is
called the *sampling distribution*.  The command `replicate()` is
useful for repeating a command a certain number of times.  For
example, we can draw 5 samples of size 10 from $N(7,1)$:

```{r}
xbar <- replicate(5, mean(rnorm(10,mean=7)))
xbar
```

Above, see how the population mean is 7 but the sample mean varies
randomly, sometimes overestimating and sometimes underestimating.  In
practice, of course, we only have a single sample and we will not know
whether the sample mean is an overestimate or an underestimate.

```{r}
hist(replicate(1e5, mean(rnorm(10,mean=7))),main="sample mean of 10 observations")
```

It turns out that the sample mean of $n$ independent observations
drawn from $N(\mu,\sigma)$ is distributed as a Gaussian with mean
$\mu$ and standard deviation $\frac{\sigma}{\sqrt{n}}$.  Symbolically:

If $x_1,\ldots,x_n\sim N(\mu,\sigma)$, then
$\overline{x}=\frac{1}{n}\sum_{i=1}^n x_i\sim
N\left(\mu,\frac{\sigma}{\sqrt{n}}\right)$.


Note how the sample mean has the correct mean of $\mu$ (the statistian
says that the sample mean is *unbiased* for the population mean).
Also see how taking more observations---that is, making $n$
larger---results in a smaller uncertainty in the estimate of $\mu$.

The quantity $\sigma/\sqrt{n}$ is known as the *standard* *error* *of*
*the* *mean*, SEM for short, or sometimes SE$[\bar{X}]$.  This shows
us how reliable our estimated mean value is.  If the SEM is small,
then our estimated mean is quite accurate, if it is large then our
estimated mean has a large uncertainty.


If

\[
\overline{x}\sim N\left(\mu,\frac{\sigma}{\sqrt{n}}\right)
\]

Then we can equally say

\[
\overline{x}-\mu\sim N\left(0,\frac{\sigma}{\sqrt{n}}\right)
\]

and so the error in using $\overline{x}$ instead of the true
value~$\mu$ is Gaussian with standard deviation $\sigma/\sqrt{n}$.

Quite often, we want to know how bad the error is likely to be.  We
would like to specify a "worst credible" error, and the standard way
to do this is to give a value for the error that is exceeded only
rarely, in particular 5\% of the time.  This is equivalent to
`qnorm(0.975)` (the value of 0.975 comes from the fact that we
specify two tails of total size 5\%, so each one is 2.5\%=0.025.  And
then because `qnorm()` takes the area to the left, we need to
specify $1-0.025=0.975$).





## Example

A zoologist is interested in the weights of a sample of 30 kiwis. 
She knows that the population standard deviation is $\sigma=0.22$.
Suppose we have a sample of 30 kiwibird weights, in kilograms:
  
```{r}
kiwi <-  c(0.57, 1.02, 0.87, 1.21, 0.69, 0.99, 1.09, 0.59,  
           0.96, 0.51, 1.36, 1.07, 0.55, 0.87, 1.24, 0.91, 
           1.22, 1.01, 1.07, 0.81, 0.98, 1.03, 0.99, 1.17, 
           1.07, 1.18, 0.95, 1, 0.9, 1.06)
```

Then we can calculate the sample mean:
  
```{r}
mean(kiwi)
```

So the estimate of the mean weight of a kiwi bird is about 0.96kg.
But how accurate is this estimate?  The true mean might be 0.93kg or
1.01kg or some other value.  To find the error in this estimate we use
the standard erro of the mean, given by the formula $\sigma/\sqrt{n}$;
here $n=30$ is the number of observations, and $\sigma$ is given by
the `sd()` function, which estimates the standard deviation:

```{r}
sd(kiwi)
```

So the standard error of the mean is 

```{r}
SEM <- sd(kiwi)/sqrt(30)
SEM
```

and this shows us that the SEM is about 0.04kg.  This is the
uncertainty of our estimate, caused by random variability.

To give a confidence interval we can use `qnorm()`:

```{r}
lower_limit <- qnorm(0.025,mean(kiwi),SEM)
upper_limit <- qnorm(0.975,mean(kiwi),SEM)
c(lower_limit,upper_limit)
```

This is equivalent to a 95\% confidence interval (see chapter 8 for a
formal definition of confidence interval; *interval* is a range of
real numbers with a specified lower and upper limits).  It means that
we can be 95\% confident that the true population mean $\mu$ is in the
range from 0.61kg to 1.32kg.

It is possible to use 99\% instead of 95\%:


```{r}
qnorm(c(0.005,0.995),mean(kiwi),SEM)
```

but observe how the interval becomes wider, as the lower limit has
decreased and the upper limit increased.
